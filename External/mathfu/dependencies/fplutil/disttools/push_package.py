#!/usr/bin/python
# Copyright 2014 Google Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Push this package and its' dependencies to a remote git repositories."""

import argparse
import json
import logging
import os
import shutil
import subprocess
import sys
import tempfile
sys.path.append(os.path.realpath(os.path.join(os.path.dirname(__file__),
                                              os.path.pardir)))
from docs import generate_docs  # pylint: disable=g-import-not-at-top

## The directory containing this file.
THIS_DIR = os.path.realpath(os.path.dirname(__file__))

## Default root directory of the project.
PROJECT_DIR = os.path.realpath(os.path.join(THIS_DIR, os.path.pardir))

## Default package configuration file.
CONFIG_JSON = os.path.realpath(os.path.join(THIS_DIR, 'config.json'))

## Prefix of git remotes generated by this script.
GIT_GENERATED_PREFIX = '__tmp_'

## Prefix applied to git remote names for upstream projects.
GIT_REMOTE_PREFIX_UPSTREAM = GIT_GENERATED_PREFIX + 'upstream_'

## Prefix applied to git remote names for local projects.
GIT_REMOTE_PREFIX_LOCAL = GIT_GENERATED_PREFIX + 'local_'


class DependencyNotFoundError(Exception):
  """Raised if a dependency isn't found."""
  pass


class ConfigJsonError(Exception):
  """Raised if there is a problem reading a config.json file."""
  pass


class GitError(Exception):
  """Raised if there is an issue with the local git configuration."""
  pass


class Subprocess(object):
  """Wrapper for subprocess to optionally display all commands excecuted.
  """

  def __init__(self):
    """Initialize the instance."""
    pass

  def display_command(self, args, **argv):
    """Display a command and optionally remove the "dryrun" arg from argv.

    Args:
      args: Command to execute.
      **argv: Arguments for this command.

    Returns:
      (run, argv) tuple where run is True if the command should be executed,
      False otherwise and argv is the filtered arguments to use the run a
      command.
    """
    filtered_argv = dict(argv)
    dryrun = False
    if 'dryrun' in argv:
      dryrun = argv.get('dryrun')
      del filtered_argv['dryrun']
    if logging.getLogger().isEnabledFor(logging.DEBUG) or dryrun:
      logging.debug(str(args) + ' ' + str(argv))
    if dryrun:
      return (False, filtered_argv)
    return (True, filtered_argv)

  def check_call(self, args, **argv):
    """Wrapper for subprocess.check_call().

    Args:
      args: Command to execute.
      **argv: Additional arguments for subprocess.Popen().

    Raises:
      subprocess.CalledProcessError:
        If the process returns a non-zero error code.
    """
    run, argv = self.display_command(args, **argv)
    if not run:
      return

    try:
      subprocess.check_call(args, **argv)
    except subprocess.CalledProcessError as e:
      logging.error(e.output)
      raise e

  def get_output(self, args, **argv):
    """Run command and get standard output.

    Args:
      args: Command to execute.
      **argv: Additional arguments for subprocess.Popen().

    Returns:
      Output string if successful.

    Raises:
      subprocess.CalledProcessError: If the process returns a non-zero
        error code.
    """
    run, argv = self.display_command(args, **argv)
    if not run:
      return ''
    p = subprocess.Popen(args, stdout=subprocess.PIPE, **argv)
    stdout, _ = p.communicate()
    if p.returncode:
      raise subprocess.CalledProcessError(
          p.returncode, '%s returned %d' % (str(args), p.returncode), stdout)
    return stdout


class Package(object):
  """Source package properties.

  Attributes:
    name: Name of the package.
    url: The URL of the upstream project.
    branch: Branch the project is pushed to in the upstream project.
    revision: Revision to sync to in the project.
    is_library: Whether this project is a library.
    third_party: If this project is a 3rd party.
    prebuilts: Whether the package is prebuilt.
    push: Whether to push this project to the branch in the upstream_url.
    fetch_dependencies: Whether to pull in dependencies of this package.  If
      this is the root package this flag is ignored as dependencies are
     explicitly specified.
    config_path: Path of the config file (relative to the package path) that
      specifies dependencies of this package.  This is optionally used when
      fetch_dependencies is True to pull dependencies of the package.  If
      this is not set it is assumed the config.json is in the same directory
      as the parent package.
    package_json: "package" dictionary parsed from the JSON file.
    path: Local path of the package.
    git_remote_upstream: Name of the git remote associated with the package's
      URL (see add_git_remotes()).
    git_remote_local: Name of the git remote associated with the package's
      path (see add_git_remotes()).
    dependencies: List of Package instances that depend upon this
      package.
    subprocess_runner: Subprocess instance used to run commands.
    working_copy: Path to git working copy used to stage changes for this
      package.
  """

  def __init__(self, package_json, subprocess_runner, working_copy,
               config_path):
    """Initialize this instance.

    Args:
      package_json: "package" dictionary read from JSON config file.
      subprocess_runner: Subprocess instance used to run commands.
      working_copy: Path to git working copy used to stage changes for this
        package.
      config_path: Path to the file the configuration was read from.

    Raises:
      ConfigJsonError: If an expected key isn't found in the JSON dictionary.
    """
    self.package_json = package_json
    self.dependencies = []
    self.name = '[unknown]'
    self.path = ''
    self.git_remote_upstream = ''
    self.git_remote_local = ''
    self.subprocess_runner = subprocess_runner
    self.working_copy = working_copy
    self.prebuilts = self.package_json.get('prebuilts', 0)
    self.revision = self.package_json.get('revision', '')
    self.fetch_dependencies = self.package_json.get('fetch_dependencies', 0)
    self.config_path = self.package_json.get('config_path', config_path)
    try:
      self.name = self.package_json['name']
      self.url = self.package_json['url']
      self.branch = self.package_json['branch']
      self.is_library = self.package_json['is_library']
      self.third_party = self.package_json['third_party']
      self.push = self.package_json['push']
    except KeyError as e:
      raise ConfigJsonError('Package %s: Unable to find value (%s)' % (
          self.name, str(e)))

  def __str__(self):
    """Convert to a string representation."""
    output_lines = ['name: %s' % self.name]
    for variable in ('path', 'url', 'branch', 'push', 'is_library',
                     'third_party', 'git_remote_upstream', 'git_remote_local',
                     'prebuilts', 'revision', 'fetch_dependencies',
                     'config_path'):
      output_lines.append('  %s: %s' % (variable, getattr(self, variable)))
    return os.linesep.join(output_lines)

  def allow_dryrun(self, dryrun):
    """Whether to enable dryruns for this project.

    Args:
      dryrun: Whether to execute a dry run.

    Returns:
      True if dryrun is set and this project's URL isn't a local filesystem
      path (only works for *nix filesystems).
    """
    return dryrun and not self.url.startswith(os.path.sep)

  def resolve_dependency_paths(self, dependencies):
    """Resolve the path of the specified dependencies.

    Args:
      dependencies: List of Package instances that are dependencies of this
        package.

    Returns:
      List of Package instances (dependencies) with paths resolved.
    """
    for dependency in dependencies:
      dependency.path = self.find_dependency(dependency.name,
                                             dependency.third_party,
                                             dependency.prebuilts)
    return dependencies

  def find_dependency(self, package_name, third_party, prebuilts):
    """Finds a dependency relative to the directory containing this script.

    This script handles differences in internal vs. external git project
    package layout.

    Args:
      package_name: Name of the package to find.
      third_party: Whether the package to find is external or third_party.
      prebuilts: Whether the package is prebuilt (binary distro).

    Returns:
      Path to the dependency.

    Raises:
      DependencyNotFoundError: If the package isn't found.
    """
    # Search the published resting place first.
    search_paths = [os.path.join(self.path, 'dependencies', package_name)]
    # If this is a 3rd party package search the external directory.
    if third_party:
      search_paths.append(os.path.join(
          self.path, os.path.sep.join([os.path.pardir] * 4), 'external',
          package_name))
    elif prebuilts:
      search_paths.append(os.path.join(
          self.path, os.path.sep.join([os.path.pardir] * 4), 'prebuilts',
          package_name))
    else:
      # If the dependent package is a library, search the directory at the same
      # level.
      if self.is_library:
        search_paths.append(os.path.join(self.path, os.path.pardir,
                                         package_name))
      else:
        # Search in the libs/ directory.
        search_paths.append(os.path.join(self.path, os.path.pardir,
                                         os.path.pardir, 'libs', package_name))

    # Convert all paths to absolute paths.
    search_paths = [os.path.realpath(p) for p in search_paths]

    # Perform the search.
    for path in search_paths:
      if os.path.isdir(path):
        return path

    raise DependencyNotFoundError('Dependency %s not found in set %s' % (
        package_name, str(search_paths)))

  def add_git_remotes(self, git_remote_name):
    """Add the git remotes for this package.

    Adds the upstream and local remote names to the
    git_remote_upstream and git_remote_local attributes.

    Args:
      git_remote_name: Local remote to use from each package.  This is only
        required if more than one remote is present in each package.  If this
        remote is not present and only *one* remote is present the sole remote
        is used instead.

    Raises:
      subprocess.CalledProcessError: If git encounters an error.
      GitError: If there is a configuration problem the git working copies.
    """
    assert self.url
    assert self.path
    # Find remotes for the local copy of the package.
    local_remotes = []
    for remote, url in Package.get_git_remotes(self.path,
                                               self.subprocess_runner):
      if not remote.startswith(GIT_GENERATED_PREFIX):
        local_remotes.append((remote, url))
    if not local_remotes:
      raise GitError('No remotes in package %s (%s).' % (self.name, self.path))

    # If a git remote name is specified, try using it.
    if git_remote_name:
      local_remotes_dict = dict(local_remotes)
      if git_remote_name in local_remotes_dict:
        local_remotes = [(git_remote_name, local_remotes_dict[git_remote_name])]

    if len(local_remotes) > 1:
      raise GitError(
          'Too many remotes (%s) in package %s.  This script can only support '
          'one remote per package.' % (str(local_remotes), self.name))

    # Add the upstream and local remotes for the package.
    self.git_remote_upstream = Package.add_git_remote(
        GIT_REMOTE_PREFIX_UPSTREAM + self.name, self.url, self.working_copy,
        self.subprocess_runner)
    _, local_url = local_remotes[0]
    self.git_remote_local = Package.add_git_remote(
        GIT_REMOTE_PREFIX_LOCAL + self.name, local_url, self.working_copy,
        self.subprocess_runner)

  def add_all_git_remotes(self, git_remote_name):
    """Add the git remotes for this package and its dependencies.

    Args:
      git_remote_name: Local remote to use from each package.  This is only
        required if more than one remote is present in each package.

    Raises:
      subprocess.CalledProcessError: If git encounters an error.
      GitError: If there is a configuration problem the git working copies.
    """
    self.add_git_remotes(git_remote_name)
    for dependency in self.dependencies:
      dependency.add_git_remotes(git_remote_name)

  @staticmethod
  def get_git_branches(working_copy_dir, subprocess_runner):
    """Get the list of git branches in the specified working copy directory.

    Args:
      working_copy_dir: Directory to query.
      subprocess_runner: Subprocess instance used to run commands.

    Returns:
      List of branch names.
    """
    branches = []
    for line in subprocess_runner.get_output(
        ['git', 'branch'], cwd=working_copy_dir).splitlines():
      branches.append(line[2:])
    return branches

  @staticmethod
  def git_remote_branch_exists(remote, branch, working_copy_dir,
                               subprocess_runner):
    """Determine whether a branch exists in the remote.

    Args:
      remote: Remote to query.
      branch: Branch to look for in the remote.
      working_copy_dir: Directory to query.
      subprocess_runner: Subprocess instance used to run commands.

    Returns:
      Complete name of the branch if present, empty string otherwise..
    """
    matches = []
    for remote_branch in Package.get_git_remote_branches(remote,
                                                         working_copy_dir,
                                                         subprocess_runner):
      if remote_branch.split('/')[1] == branch:
        matches.append(remote_branch)
    if not matches:
      return ''
    return matches[0]

  @staticmethod
  def get_git_remote_branches(remote, working_copy_dir, subprocess_runner):
    """Get the list of git branches in the specified remote.

    Args:
      remote: Remote to query.
      working_copy_dir: Directory to query.
      subprocess_runner: Subprocess instance used to run commands.

    Returns:
      List of branch names.
    """
    branches = []
    for line in subprocess_runner.get_output(
        ['git', 'branch', '-r'], cwd=working_copy_dir).splitlines():
      remote_branch = line[2:]
      if remote_branch.startswith(remote + '/'):
        branches.append(remote_branch)
    return branches

  @staticmethod
  def get_git_remotes(working_copy_dir, subprocess_runner):
    """Get the list of git remotes in the specified working copy directory.

    Args:
      working_copy_dir: Directory to query.
      subprocess_runner: Subprocess instance used to run commands.

    Returns:
      Set of (remote_name, url) tuples where remote_name is the name of the
      remote and url is the URL the remote references.
    """
    remotes = set()
    for line in subprocess_runner.get_output(
        ['git', 'remote', '-v'], cwd=working_copy_dir).splitlines():
      remotes.add(' '.join(line.split()[:2]))
    return [pair.split() for pair in remotes]

  @staticmethod
  def add_git_remote(git_remote_name, remote_url, working_copy_dir,
                     subprocess_runner):
    """Add the git specified git remote if it doesn't already exist.

    Args:
      git_remote_name: Name of the remote.
      remote_url: URL remote name points to.
      working_copy_dir: Directory to add git remote to.
      subprocess_runner: Subprocess instance used to run commands.

    Returns:
      Name of the remote.

    Raises:
      subprocess.CalledProcessError: If git encounters an error.
      GitError: If the remote already exists with an unexpected URL.
    """
    for remote_name, url in Package.get_git_remotes(working_copy_dir,
                                                    subprocess_runner):
      if git_remote_name == remote_name:
        if remote_url != url:
          raise GitError(
              'Remote %s already exists with unexpected URL %s '
              '(expected %s)' % (git_remote_name, url, remote_url))
        return git_remote_name
    subprocess_runner.check_call(['git', 'remote', 'add', git_remote_name,
                                  remote_url], cwd=working_copy_dir)
    return git_remote_name

  def fetch_remotes(self):
    """Fetch remotes referenced by this package.

    Raises:
      subprocess.CalledProcessError: If git encounters an error.
    """
    assert self.git_remote_upstream
    assert self.git_remote_local
    for remote in (self.git_remote_upstream, self.git_remote_local):
      self.subprocess_runner.check_call(['git', 'remote', 'update', remote],
                                        cwd=self.working_copy)

  def fetch_all_remotes(self):
    """Fetch remotes referenced by this package and its dependencies.

    Raises:
      subprocess.CalledProcessError: If git encounters an error.
    """
    self.fetch_remotes()
    for dependency in self.dependencies:
      dependency.fetch_all_remotes()

  def checkout_clean_branch(self, remote, branch):
    """Checkout a branch and clean the git working copy of the package.

    Args:
      remote: Remote the branch is on.
      branch: Remote branch to checkout.

    Raises:
      subprocess.CalledProcessError: If git encounters an error.
    """
    remote_branch = '/'.join((remote, branch))
    local_branch_name = GIT_GENERATED_PREFIX + remote_branch
    if local_branch_name in Package.get_git_branches(self.working_copy,
                                                     self.subprocess_runner):
      self.delete_git_branch(local_branch_name)
    self.subprocess_runner.check_call(
        ['git', 'checkout', '-b', local_branch_name, remote_branch],
        cwd=self.working_copy)
    self.subprocess_runner.check_call(['git', 'clean', '-dfx'],
                                      cwd=self.working_copy)
    self.subprocess_runner.check_call(['git', 'submodule', 'update', '--init',
                                       '--recursive'], cwd=self.working_copy)

  def push_git_project(self, local_branch_name, dryrun):
    """Push this package to git branch and remote.

    Args:
      local_branch_name: Name of the local branch (in the local remote)
        to push.
      dryrun: Don't actually perform the push just print the command.
        This is ignored if the repository is a local filesystem path
        (only *nix style filesystems) since this is useful for testing.

    Raises:
      subprocess.CalledProcessError: If git encounters an error.
    """
    assert self.git_remote_upstream
    assert self.git_remote_local
    # Checkout the local branch.
    self.checkout_clean_branch(self.git_remote_local, local_branch_name)
    # Push the head to the remote branch.
    # If this is a local filesystem path, unconditionally push to it.
    self.subprocess_runner.check_call(
        ['git', 'push', self.git_remote_upstream, 'HEAD:%s' % self.branch],
        cwd=self.working_copy,
        dryrun=self.allow_dryrun(dryrun))

  def push_git_project_and_dependencies(self, local_branch_name, dryrun):
    """Push this project and its dependencies their remotes.

    This package is pushed without dependencies embedded as submodules.
    In addition, this only pushes a dependency if the "push" attribute is True.

    Args:
      local_branch_name: Name of the local branch (in the local remote)
        to push in each dependent package.
      dryrun: Don't actually perform the push just print the commands.

    Raises:
      subprocess.CalledProcessError: If git encounters an error.
    """
    self.push_git_project(local_branch_name, dryrun)
    for dependency in self.dependencies:
      if dependency.push:
        dependency.push_git_project(local_branch_name, dryrun)

  def update_master(self, local_branch_name, master_branch, dryrun):
    """Update the master branch with the dependencies of this package.

    Args:
      local_branch_name: Name of the local branch (in the local remote)
        to push to the master_branch.
      master_branch: Name of the upstream "master" branch to push to.
      dryrun: Don't actually perform the push just print the commands.

    Raises:
      GitError: If a dependent package references more than one remote.
      subprocess.CalledProcessError: If git encounters an error.
    """
    # Update all remotes to make sure we have all dependencies in the index.
    self.subprocess_runner.check_call(
        ['git', 'remote', 'update'], cwd=self.working_copy)

    # Merge the local branch into a local copy of the upstream branch.
    remote_master_branch = Package.git_remote_branch_exists(
        self.git_remote_upstream, master_branch, self.working_copy,
        self.subprocess_runner)
    if remote_master_branch:
      self.checkout_clean_branch(self.git_remote_upstream, master_branch)
    else:
      self.checkout_clean_branch(self.git_remote_local, local_branch_name)
    self.subprocess_runner.check_call(
        ['git', 'merge', '/'.join((self.git_remote_local, local_branch_name)),
         '-m', 'Merge internal branch into %s' % master_branch],
        cwd=self.working_copy)

    # Add dependencies as submodules.
    dependencies_dir = os.path.join(self.working_copy, 'dependencies')
    if not os.path.exists(dependencies_dir):
      os.makedirs(dependencies_dir)
    dependencies_commit_message = ['Updated dependencies.', '']
    for dependency in self.dependencies:
      submodule_path = os.path.join(dependencies_dir, dependency.name)
      if not os.path.exists(submodule_path):
        os.mkdir(submodule_path)
        self.subprocess_runner.check_call(
            ['git', 'clone', '-b', dependency.branch, dependency.url,
             submodule_path], cwd=submodule_path)

        # NOTE: The submodule path needs to be relative to the working copy.
        # Also, submodule add occasionally complains about the directory
        # being ignored by .gitignore (it's not) so force the add.
        self.subprocess_runner.check_call(
            ['git', 'submodule', 'add', '-f', dependency.url,
             os.path.join(os.path.basename(dependencies_dir),
                          dependency.name)], cwd=self.working_copy)
      if dependency.revision:
        self.subprocess_runner.check_call(
            ['git', 'reset', '--hard', dependency.revision],
            cwd=submodule_path)
        self.subprocess_runner.check_call(
            ['git', 'add', submodule_path], cwd=self.working_copy)

      submodule_remotes = Package.get_git_remotes(submodule_path,
                                                  self.subprocess_runner)
      if len(submodule_remotes) > 1:
        raise GitError('Dependency %s references more than one remote (%s)' %
                       (dependency.name, str(submodule_remotes)))
      remote_name, _ = submodule_remotes[0]

      self.subprocess_runner.check_call(
          ['git', 'checkout', '-q', '/'.join(
              (remote_name, dependency.branch))], cwd=submodule_path)
      # TODO: revisit this see similar reset --hard above.
      if dependency.revision:
        self.subprocess_runner.check_call(
            ['git', 'reset', '--hard', dependency.revision],
            cwd=submodule_path)
      dependencies_commit_message.append(self.subprocess_runner.get_output(
          ['git', 'log', '-n', '1', '--oneline'], cwd=submodule_path))

    if self.subprocess_runner.get_output(
        ['git', 'status', '-s'], cwd=self.working_copy):
      self.subprocess_runner.check_call(
          ['git', 'add', '-A'], cwd=self.working_copy)
      self.subprocess_runner.check_call(
          ['git', 'commit', '-a', '-m',
           os.linesep.join(dependencies_commit_message)],
          cwd=self.working_copy)
    # Force upstream push if the project URL is on the local filesystem.
    self.subprocess_runner.check_call(
        ['git', 'push', self.git_remote_upstream, 'HEAD:%s' % master_branch],
        cwd=self.working_copy,
        dryrun=self.allow_dryrun(dryrun))

  # TODO(smiles): Add method that tags the release?

  def update_docs(self, branch, docs_branch, dryrun):
    """Update the documentation for the project and push to gh-pages.

    Args:
      branch: Name of branch to build the docs from.
      docs_branch: Name of the branch to push the docs to.
      dryrun: Don't actually perform the push just print the commands.

    Raises:
      subprocess.CalledProcessError: If the docs generation fails.
    """
    self.checkout_clean_branch(self.git_remote_local, branch)
    docs_dir = os.path.join(self.working_copy, 'docs')
    docs_src_dir = os.path.join(docs_dir, 'src')
    doc_info = self.subprocess_runner.get_output(
        ['git', 'log', '-n', '1', '--oneline', docs_dir],
        cwd=self.working_copy)
    doc_hash = doc_info.split()[0]
    docs_commit_message = ['Update docs to %s' % doc_hash, '', doc_info]
    sys_argv = sys.argv
    try:
      # TODO(smiles): Change the docs script so that it's possible to call it
      # directly and get the output directory rather than implicitly assuming
      # docs are placed under docs/html.
      sys.argv = [sys.argv[0], '--source-dir', docs_src_dir,
                  '--linklint-dir', docs_dir,
                  '--project-dir', self.working_copy]
      docs_output = os.path.join(docs_dir, 'html')
      if generate_docs.main():
        raise subprocess.CalledProcessError(1, 'Failed to generate docs.')
    finally:
      sys.argv = sys_argv
    # Temporary directory used to save the docs.
    docs_temp = tempfile.mkdtemp()
    try:
      # Move the HTML output of the build process to the temporary docs dir.
      shutil.move(docs_output, docs_temp)

      # Clean the working copy and reset to the docs branch.
      dependencies_dir = os.path.join(self.working_copy, 'dependencies')
      if os.path.exists(dependencies_dir):
        shutil.rmtree(dependencies_dir)
      self.subprocess_runner.check_call(['git', 'submodule', 'deinit', '.'],
                                        cwd=self.working_copy)
      if Package.git_remote_branch_exists(self.git_remote_upstream,
                                          docs_branch, self.working_copy,
                                          self.subprocess_runner):
        self.checkout_clean_branch(self.git_remote_upstream, docs_branch)
      else:
        self.subprocess_runner.check_call(
            ['git', 'checkout', '--orphan',
             GIT_GENERATED_PREFIX + docs_branch], cwd=self.working_copy)
      self.subprocess_runner.check_call(['git', 'rm', '-rf', '.'],
                                        cwd=self.working_copy)
      self.subprocess_runner.check_call(['git', 'clean', '-dfx'],
                                        cwd=self.working_copy)

      # Move the docs back into the working copy.
      final_doc_set = os.path.join(docs_temp, os.path.basename(docs_output))
      for filename in os.listdir(final_doc_set):
        shutil.move(os.path.join(final_doc_set, filename), self.working_copy)
      # Commit the modified documentation.
      self.subprocess_runner.check_call(['git', 'add', '-A'],
                                        cwd=self.working_copy)
      if self.subprocess_runner.get_output(
          ['git', 'status', '-s'], cwd=self.working_copy):
        self.subprocess_runner.check_call(
            ['git', 'commit', '-a', '-m',
             os.linesep.join(docs_commit_message)],
            cwd=self.working_copy)
        # Push the change.
        self.subprocess_runner.check_call(
            ['git', 'push', self.git_remote_upstream, 'HEAD:%s' % docs_branch],
            cwd=self.working_copy, dryrun=self.allow_dryrun(dryrun))

    finally:
      shutil.rmtree(docs_temp)

  @staticmethod
  def parse_root_json(config_json, config_path, project_path, subprocess_runner,
                      working_copy):
    """Parse root package from a dictionary read from a config.json file.

    Args:
      config_json: Dictionary parsed from config.json file.
      config_path: Path of the file config_json was parsed from (relative to
        the project).
      project_path: Local path to the project containing the config.json file.
      subprocess_runner: Subprocess instance used to run commands.
      working_copy: Directory to stage git changes in.

    Returns:
      Package instance representing the root package in the config file which
      should reference a set of dependencies.

    Raises:
      ConfigJsonError: If an expected key isn't found in the JSON dictionary.
    """
    try:
      package_dict = config_json['package']
    except KeyError as e:
      raise ConfigJsonError('Package [root] not found: (%s)' % str(e))
    package = Package(package_dict, subprocess_runner, working_copy,
                      config_path)
    package.path = os.path.realpath(project_path)
    return package

  def parse_dependencies_json(self, config_json, subprocess_runner,
                              working_copy, config_reader, parent_package):
    """Parse dependencies from a dictionary read from a config.json file.

    All dependencies are added to the "dependencies" attribute.

    Args:
      config_json: Dictionary parsed from config.json file.
      subprocess_runner: Subprocess instance used to run commands.
      working_copy: Directory to stage git changes in.
      config_reader: Callable that read_config()'s signature used to recursively
        read dependencies of the package.
      parent_package: Package instance which is a parent of the dependencies
        specified in config_json.

    Raises:
      ConfigJsonError: If an expected key isn't found in the JSON dictionary.
    """
    try:
      dependencies_list = config_json['dependencies']
    except KeyError as e:
      raise ConfigJsonError('Dependencies not found: (%s)' % str(e))

    # Parse packages from the config and resolve all packages.
    additional_dependencies = parent_package.resolve_dependency_paths(
        [Package(dependency_dict, subprocess_runner, working_copy,
                 parent_package.config_path)
         for dependency_dict in dependencies_list])

    # Extend the list of dependencies with newly discovered packages.
    path_dependency_dict = dict([(d.path, d) for d in self.dependencies])
    new_dependencies = []
    for dependency in additional_dependencies:
      if (dependency.path not in path_dependency_dict and
          dependency.path != self.path):
        path_dependency_dict[dependency.path] = dependency
        new_dependencies.append(dependency)
    self.dependencies = path_dependency_dict.values()

    # Recursively read dependencies.
    for dependency in new_dependencies:
      if dependency.fetch_dependencies:
        self.parse_dependencies_json(
            config_reader(os.path.join(dependency.path,
                                       dependency.config_path)),
            subprocess_runner, working_copy, config_reader, dependency)

  @staticmethod
  def parse_json(config_json, config_path, project_path, subprocess_runner,
                 working_copy, config_reader):
    """Parse dictionary read from a config.json file.

    Args:
      config_json: Dictionary parsed from config.json file.
      config_path: Path of the file config_json was parsed from (relative to
        the project).
      project_path: Local path to the project containing the config.json file.
      subprocess_runner: Subprocess instance used to run commands.
      working_copy: Directory to stage git changes in.
      config_reader: Callable that read_config()'s signature used to recursively
        read dependencies of the package.

    Returns:
      Package instance representing the root package in the config file which
      should reference a set of dependencies.

    Raises:
      ConfigJsonError: If an expected key isn't found in the JSON dictionary.
    """
    package = Package.parse_root_json(config_json, config_path, project_path,
                                      subprocess_runner, working_copy)
    package.parse_dependencies_json(config_json, subprocess_runner,
                                    working_copy, config_reader, package)
    return package

  def delete_git_branch(self, branch):
    """Delete branch in the package's working copy.

    Args:
      branch: Name of the branch to delete.
    """
    self.subprocess_runner.check_call(
        ['git', 'checkout', '-q', '--detach'], cwd=self.working_copy)
    self.subprocess_runner.check_call(
        ['git', 'branch', '-D', branch], cwd=self.working_copy)

  def delete_temporary_git_objects(self):
    """Delete temporary git objects created by this module.

    Raises:
      subprocess.CalledProcessError: If git encounters an error.
    """
    for remote, _ in Package.get_git_remotes(self.working_copy,
                                             self.subprocess_runner):
      if remote.startswith(GIT_GENERATED_PREFIX):
        self.subprocess_runner.check_call(
            ['git', 'remote', 'rm', remote], cwd=self.working_copy)

    for branch in Package.get_git_branches(self.working_copy,
                                           self.subprocess_runner):
      if branch.startswith(GIT_GENERATED_PREFIX):
        self.delete_git_branch(branch)

    for dependency in self.dependencies:
      dependency.delete_temporary_git_objects()

  def create_mirror(self, mirror_dir):
    """Create mirror of this package and it's dependencies.

    Args:
      mirror_dir: Directory where mirror will be stored.

    Raises:
      OSError: If this method fails to create mirror.
    """
    ignore_git = shutil.ignore_patterns('.git')
    logging.debug('Copying %s to %s', self.path, mirror_dir)
    shutil.copytree(self.path, mirror_dir, ignore=ignore_git)
    dependencies_dir = os.path.join(mirror_dir, 'dependencies')
    logging.debug('Creating ' + dependencies_dir)
    os.mkdir(dependencies_dir)
    for dependency in self.dependencies:
      mirrored_dependency = os.path.join(dependencies_dir, dependency.name)
      logging.debug('Copying %s to %s ', dependency.path, mirrored_dependency)
      shutil.copytree(dependency.path, mirrored_dependency, ignore=ignore_git)


def read_config(config_filename):
  """Read the configuration of the specified package.

  Args:
    config_filename: JSON file to read from config_dir.

  Returns:
    Dictionary read from the config.json file.

  Raises:
    ConfigJsonError: If the config.json file isn't found or it's
      malformed.
  """
  try:
    with open(config_filename) as fileobject:
      return json.load(fileobject)
  except (OSError, ValueError) as error:
    raise ConfigJsonError('Unable to read %s (%s)' % (
        config_filename, str(error)))


def display_package(package, logging_callable):
  """Display a package with all dependencies.

  Args:
    package: Package to display.
    logging_callable: Method called to log the package.
  """
  logging_callable(str(package))
  for dep in package.dependencies:
    logging_callable(str(dep))


def parse_arguments(project_dir=None, config_json=None):
  """Parse arguments for this script.

  Args:
    project_dir: Default project directory.
    config_json: Default config.json filename.

  Returns:
    Result of argparse.ArgumentParser.parse_args().
  """
  parser = argparse.ArgumentParser()
  parser.add_argument('-v', '--verbose', help='Display verbose output.',
                      action='store_true')
  parser.add_argument('-d', '--dryrun',
                      help=('Do not push changes upstream. NOTE: This '
                            'can cause problems when adding submodules '
                            'if the dependencies are not pushed upstream.'),
                      action='store_true')
  parser.add_argument('-L', '--leave-working-copy',
                      help='Do not clean up the git staging area.',
                      action='store_true')
  parser.add_argument('-s', '--staging-area',
                      help='Directory for staging changes.')
  parser.add_argument('-b', '--local-branch', required=True,
                      help='Local name branch to push in each dependency.')
  parser.add_argument('-m', '--master-branch', default='master',
                      help='Name of the remote master branch to update.')
  parser.add_argument('-r', '--remote-name', default='',
                      help=('Optional name of the git remote for each package.'
                            '  This is preferentially used to select a remote '
                            'when more than one remote exists in a package.'))
  parser.add_argument('-i', '--docs-branch', default='gh-pages',
                      help='Name of the remote docs branch to update.')
  parser.add_argument('--push-docs', action='store_true',
                      help=('Push documentation upstream.  '
                            'Use with care, documentation is public as soon '
                            'as it is pushed.'))
  parser.add_argument('-p', '--package-dir',
                      default=project_dir if project_dir else PROJECT_DIR,
                      help='Directory containing the package.')
  parser.add_argument('-c', '--config-json',
                      default=config_json if config_json else CONFIG_JSON,
                      help='JSON file that describes the package contents.')
  parser.add_argument('-M', '--create-mirror',
                      help=('Create a mirror in the specified directory for '
                            'testing.  NOTE: This disables all git publishing '
                            'operations.'))
  return parser.parse_args()


def main(args=None):
  """Push this package and its' dependencies to a remote git repositories.

  Gather the git repository of this package and its' dependencies, specified
  by a JSON configuration file, and push the result to a remote git repository.
  In addition, create a "master" branch on the remote that contains this
  package's dependencies under the "dependencies" directory as submodules.
  Finally, build the documentation using the "docs/generate_docs.py" script for
  this package and push the HTML output to a "gh-pages" branch in the remote
  repo.

  Args:
    args: The result of parse_arguments().

  Returns:
    0 if all dependencies are found, 1 otherwise.
  """
  args = args if args else parse_arguments()

  subprocess_runner = Subprocess()
  if args.staging_area:
    working_copy = os.path.realpath(args.staging_area)
  else:
    working_copy = tempfile.mkdtemp()

  # Create a directory inside the `staging area` with the project name.
  project_name = os.path.basename(args.package_dir)
  working_copy = os.path.join(working_copy, project_name)
  os.mkdir(working_copy)

  logging.basicConfig(format='%(message)s')
  logging.getLogger().setLevel(
      logging.DEBUG if args.verbose else logging.INFO)

  if args.create_mirror:
    logging.info('mirror target directory: %s', args.create_mirror)
  elif args.verbose or args.leave_working_copy:
    logging.info('git staging area in: %s', working_copy)
  try:
    subprocess_runner.check_call(['git', 'init'], cwd=working_copy)
    try:
      config_path = os.path.relpath(args.config_json, args.package_dir)
      package = Package.parse_json(read_config(args.config_json),
                                   config_path, args.package_dir,
                                   subprocess_runner, working_copy, read_config)
    except (ConfigJsonError, DependencyNotFoundError) as error:
      logging.error(str(error))
      return 1

    if args.create_mirror:
      display_package(package, logging.info)
      package.create_mirror(args.create_mirror)
      return 0

    try:
      logging.info('===== Adding Remotes ====')
      package.add_all_git_remotes(args.remote_name)
      display_package(package, logging.debug)
      logging.info('===== Fetching Remotes ====')
      package.fetch_all_remotes()
      logging.info('===== Pushing Dependencies ====')
      package.push_git_project_and_dependencies(args.local_branch, args.dryrun)
      logging.info('===== Updating Master ====')
      package.update_master(args.local_branch, args.master_branch, args.dryrun)
      logging.info('===== Updating Docs ====')
      package.update_docs(args.local_branch, args.docs_branch,
                          args.dryrun or not args.push_docs)
    finally:
      if not args.leave_working_copy:
        package.delete_temporary_git_objects()
  finally:
    if not args.leave_working_copy and not args.staging_area:
      shutil.rmtree(working_copy)

  return 0


if __name__ == '__main__':
  sys.exit(main())
